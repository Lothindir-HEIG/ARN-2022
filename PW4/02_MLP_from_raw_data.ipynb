{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic-cqm0tbUc3"
      },
      "source": [
        "# Multilayer Perceptron from raw data\n",
        "This notebook will guide you through the use of the `keras` package to train a multilayer perceptron for handwritten digits classification. You are going to use the `mnist` dataset from LeCun et al. 1998"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND1Cf9lXbUc6"
      },
      "source": [
        "## Loading the packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pvq0DhLtbUdE"
      },
      "outputs": [],
      "source": [
        "#%pip install tensorflow --upgrade\n",
        "#%pip install keras --upgrade\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as pl\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.utils import np_utils\n",
        "from sklearn import metrics as me\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWYVnpuJ3nVR"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(conf_matrix, classes_names):\n",
        "    fig, ax = pl.subplots()\n",
        "    im = ax.imshow(conf_matrix, cmap=\"viridis\")\n",
        "\n",
        "    # Show all ticks and label them with the respective list entries\n",
        "    ax.set_xticks(np.arange(len(classes_names)))#, labels=classes_names)\n",
        "    ax.set_yticks(np.arange(len(classes_names)))#, labels=classes_names)\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    pl.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    for i in range(len(classes_names)):\n",
        "        for j in range(len(classes_names)):\n",
        "            text = ax.text(j, i, conf_matrix[i, j], fontweight=\"bold\", fontsize=\"large\", ha=\"center\", va=\"center\", c=\"r\")\n",
        "\n",
        "    pl.title('Confusion matrix')\n",
        "    pl.xlabel('Predicted')\n",
        "    pl.ylabel('Excpected')\n",
        "    fig.set_figwidth(7)\n",
        "    fig.set_figheight(7)\n",
        "    fig.tight_layout()\n",
        "    pl.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vy0wRnm2bUde"
      },
      "source": [
        "## Using raw data to train a MLP\n",
        "First load the `mnist` dataset and normalize it to be in the range [0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CKuJwcibUdi",
        "outputId": "640d6b08-26f9-4dfe-df7a-205ab761871f"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "n_classes = 10\n",
        "# convert class vectors to binary class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, n_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01XwVeDNbUdv"
      },
      "source": [
        "Create the MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "DNgzrBJEbUd0",
        "outputId": "dfe70cb8-d10c-4735-93c7-3a101a15fdb7"
      },
      "outputs": [],
      "source": [
        "model = Sequential(name=\"MLP-raw\")\n",
        "model.add(Dense(256, input_shape=(784,), activation='relu', name=\"Input\"))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(n_classes, activation='softmax', name=\"Output\"))\n",
        "\n",
        "model.summary()\n",
        "plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Peiq9GR2bUeN"
      },
      "source": [
        "Define some constants and train the MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBt-ReqIbUeR",
        "outputId": "3a0566ad-abf3-4e77-c879-1fbf784a54b8"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "n_epoch = 20\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    batch_size=batch_size, epochs=n_epoch,\n",
        "                    verbose=1, validation_data=(X_test, Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u_zpHr5bUeb"
      },
      "source": [
        "Show the performance of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "PHXi21E1bUef",
        "outputId": "43ddeccf-3430-4642-d026-e140a172a341"
      },
      "outputs": [],
      "source": [
        "pl.plot(history.history['loss'], label='Training')\n",
        "pl.plot(history.history['val_loss'], label='Testing')\n",
        "pl.title(f'Loss over time')\n",
        "pl.xlabel('Epoch')\n",
        "pl.ylabel('Loss')\n",
        "pl.legend()\n",
        "pl.grid()\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(f'Test score: {round(score[0], 4)}')\n",
        "print(f'Test accuracy: {round(score[1]*100, 2)}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLuFK6MobUet"
      },
      "source": [
        "Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "PAjwjjrjbUex",
        "outputId": "0011e0be-a08b-4bd7-d999-991603b03a66"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(X_test)\n",
        "pred = np.argmax(pred, axis=-1)\n",
        "cm = me.confusion_matrix(y_test, pred)\n",
        "classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "plot_confusion_matrix(cm, classes)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "02_MLP_from_raw_data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
